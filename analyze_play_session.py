#!/usr/bin/env python3
"""
ë†€ì´ ì„¸ì…˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- ì•„ë™ ë°œí™” ë¶„ì„
- ì£¼ì œ/í† í”½ ì¶”ì¶œ
- ê°ì • ë¶„ì„
- ìƒí˜¸ì‘ìš© íŒ¨í„´ ë¶„ì„
"""

import json
import os
import re
from pathlib import Path
from collections import Counter, defaultdict
from datetime import datetime
import statistics

class PlaySessionAnalyzer:
    """ë†€ì´ ì„¸ì…˜ ë¶„ì„ê¸°"""
    
    def __init__(self, session_dir):
        """
        Args:
            session_dir: ì„¸ì…˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: raw_data/20251017-ì´ë¯¼ì •êµì‚¬-ê¹€ì¤€ìš°-ë§Œ4ì„¸-02_00_48-65kbps_mono)
        """
        self.session_dir = Path(session_dir)
        self.session_name = self.session_dir.name
        
        # ë””ë ‰í† ë¦¬ êµ¬ì¡°
        self.vtt_dir = self.session_dir / "vtt"
        self.ai_response_dir = self.session_dir / "ai_response"
        self.feature_dir = self.session_dir / "feature"
        self.meta_path = self.session_dir / "meta.json"
        
        # ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.meta_info = {}
        self.dialogues = []  # [{speaker, text, start_time, end_time, segment}]
        self.segments = []  # 2ë¶„ ë‹¨ìœ„ ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´
        
        # ê°ì • í‚¤ì›Œë“œ ì‚¬ì „ (í•œêµ­ì–´)
        self.positive_keywords = [
            'ì¢‹ì•„', 'ì¬ë°Œ', 'ì‹ ê¸°', 'ë©‹ì§€', 'ìš°ì™€', 'ì™€', 'ì˜ˆì˜', 'í–‰ë³µ', 
            'ì¦ê±°', 'ì›ƒ', 'í•˜í•˜', 'íˆíˆ', 'ì‘', 'ë„¤', 'ê°ì‚¬', 'ê³ ë§ˆì›Œ',
            'ì‚¬ë‘', 'ìµœê³ ', 'ëŒ€ë°•', 'êµ¿', 'ì¢‹ë‹¤', 'ê´œì°®', 'ê·¸ë˜'
        ]
        
        self.negative_keywords = [
            'ì‹«', 'ì•ˆë¼', 'ì•„ë‹ˆ', 'ìŠ¬í¼', 'ë¬´ì„œ', 'ì•„íŒŒ', 'í˜ë“¤', 'ì§œì¦',
            'í™”ë‚˜', 'ë¯¸ì›Œ', 'ë‚˜ë¹ ', 'ì†ìƒ', 'ìš°', 'ì—‰ì—‰', 'ì•ˆì¢‹', 'ë³„ë¡œ',
            'ì‹¤ë§', 'ê±±ì •', 'ë¶ˆì•ˆ'
        ]
        
        # ë¬¸ì œí•´ê²° ê´€ë ¨ í‚¤ì›Œë“œ
        self.problem_solving_keywords = [
            'ì–´ë–»ê²Œ', 'ì™œ', 'ë°©ë²•', 'ìƒê°', 'í•´ê²°', 'ì°¾', 'ë§Œë“¤', 'í•´ë´',
            'í•´ë³¼ê¹Œ', 'í•˜ë©´', 'ì´ë ‡ê²Œ', 'ì €ë ‡ê²Œ', 'ë„ì™€', 'ê°™ì´', 'í•¨ê»˜',
            'ì´ìœ ', 'ê¹Œë‹­', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ¬ë©´', 'ê·¸ëŸ¼'
        ]
        
    def parse_filename_info(self):
        """íŒŒì¼ëª…ì—ì„œ ë©”íƒ€ ì •ë³´ ì¶”ì¶œ"""
        # ì˜ˆ: 20251017-ì´ë¯¼ì •êµì‚¬-ê¹€ì¤€ìš°-ë§Œ4ì„¸-02_00_48-65kbps_mono
        parts = self.session_name.split('-')
        
        info = {
            'date': parts[0] if len(parts) > 0 else '',
            'teacher_name': '',
            'child_name': '',
            'child_age': '',
            'duration': '',
            'session_name': self.session_name
        }
        
        # êµì‚¬ ì´ë¦„ ì¶”ì¶œ (ëì— "êµì‚¬"ê°€ ë¶™ìŒ)
        for part in parts:
            if 'êµì‚¬' in part:
                info['teacher_name'] = part.replace('êµì‚¬', '')
                break
        
        # ë‚˜ì´ ì¶”ì¶œ (ë§ŒXì„¸)
        for part in parts:
            if 'ë§Œ' in part and 'ì„¸' in part:
                info['child_age'] = part
                break
        
        # ì•„ì´ ì´ë¦„ì€ êµì‚¬ ë‹¤ìŒ íŒŒíŠ¸
        if len(parts) > 2:
            info['child_name'] = parts[2]
        
        # ì‹œê°„ ì •ë³´
        if len(parts) > 3:
            time_part = parts[3]
            info['duration'] = time_part
            
        return info
    
    def load_meta_info(self):
        """ë©”íƒ€ ì •ë³´ ë¡œë“œ (ìˆëŠ” ê²½ìš°)"""
        if self.meta_path.exists():
            with open(self.meta_path, 'r', encoding='utf-8') as f:
                self.meta_info = json.load(f)
                # session_nameì´ ì—†ìœ¼ë©´ ì¶”ê°€
                if 'session_name' not in self.meta_info:
                    self.meta_info['session_name'] = self.session_name
        else:
            self.meta_info = self.parse_filename_info()
        
        return self.meta_info
    
    def parse_vtt_file(self, vtt_path):
        """VTT íŒŒì¼ íŒŒì‹±"""
        dialogues = []
        
        with open(vtt_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # VTT ì—”íŠ¸ë¦¬ íŒŒì‹± (íƒ€ì„ìŠ¤íƒ¬í”„ + í…ìŠ¤íŠ¸)
        pattern = r'(\d{2}:\d{2}:\d{2}\.\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}\.\d{3})\s*\n\[([^\]]+)\]\s*(.+?)(?=\n\n|\Z)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for start_time, end_time, speaker, text in matches:
            # í™”ì ë¶„ë¥˜
            speaker_type = 'teacher' if ('êµì‚¬' in speaker or 'ì„ ìƒë‹˜' in speaker) else 'child'
            
            dialogues.append({
                'start_time': start_time,
                'end_time': end_time,
                'speaker': speaker.strip(),
                'speaker_type': speaker_type,
                'text': text.strip()
            })
        
        return dialogues
    
    def load_all_dialogues(self):
        """ëª¨ë“  VTT íŒŒì¼ì—ì„œ ëŒ€í™” ë¡œë“œ"""
        all_dialogues = []
        
        # _subtitle.vtt íŒŒì¼ ìš°ì„  (í›„ì²˜ë¦¬ëœ ë²„ì „)
        vtt_files = sorted(self.vtt_dir.glob("*_subtitle.vtt"))
        
        if not vtt_files:
            # subtitle.vttê°€ ì—†ìœ¼ë©´ ë¯¸ì²˜ë¦¬/í›„ì²˜ë¦¬ ë²„ì „ ì‚¬ìš©
            vtt_files = sorted(self.vtt_dir.glob("*.vtt"))
        
        for vtt_file in vtt_files:
            # ì„¸ê·¸ë¨¼íŠ¸ ì‹œê°„ ì •ë³´ ì¶”ì¶œ (ì˜ˆ: 000-002ë¶„)
            segment_match = re.search(r'_(\d{3}-\d{3})ë¶„', vtt_file.name)
            segment = segment_match.group(1) if segment_match else ''
            
            dialogues = self.parse_vtt_file(vtt_file)
            
            # ì„¸ê·¸ë¨¼íŠ¸ ì •ë³´ ì¶”ê°€
            for d in dialogues:
                d['segment'] = segment
                d['segment_file'] = vtt_file.name
            
            all_dialogues.extend(dialogues)
        
        self.dialogues = all_dialogues
        return all_dialogues
    
    def analyze_speech_ratio(self):
        """ë°œí™” ë¹„ìœ¨ ë¶„ì„"""
        teacher_count = 0
        child_count = 0
        teacher_words = 0
        child_words = 0
        
        for d in self.dialogues:
            word_count = len(d['text'])
            
            if d['speaker_type'] == 'teacher':
                teacher_count += 1
                teacher_words += word_count
            else:
                child_count += 1
                child_words += word_count
        
        total_count = teacher_count + child_count
        total_words = teacher_words + child_words
        
        return {
            'child_speech_ratio': (child_count / total_count * 100) if total_count > 0 else 0,
            'child_utterance_count': child_count,
            'teacher_utterance_count': teacher_count,
            'total_utterance_count': total_count,
            'child_words': child_words,
            'teacher_words': teacher_words,
            'total_words': total_words,
            'child_word_ratio': (child_words / total_words * 100) if total_words > 0 else 0,
        }
    
    def analyze_child_speech_amount(self):
        """ì•„ë™ ë°œí™”ì–‘ ë¶„ì„"""
        child_dialogues = [d for d in self.dialogues if d['speaker_type'] == 'child']
        
        if not child_dialogues:
            return {
                'total_utterances': 0,
                'total_characters': 0,
                'avg_utterance_length': 0,
                'longest_utterance': 0,
                'shortest_utterance': 0
            }
        
        utterance_lengths = [len(d['text']) for d in child_dialogues]
        
        return {
            'total_utterances': len(child_dialogues),
            'total_characters': sum(utterance_lengths),
            'avg_utterance_length': statistics.mean(utterance_lengths),
            'longest_utterance': max(utterance_lengths),
            'shortest_utterance': min(utterance_lengths),
            'utterance_length_std': statistics.stdev(utterance_lengths) if len(utterance_lengths) > 1 else 0
        }
    
    def analyze_emotion_keywords(self):
        """ê°ì • í‚¤ì›Œë“œ ë¶„ì„"""
        child_texts = [d['text'] for d in self.dialogues if d['speaker_type'] == 'child']
        all_child_text = ' '.join(child_texts)
        
        # ê¸ì •/ë¶€ì • í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        positive_count = sum(all_child_text.count(keyword) for keyword in self.positive_keywords)
        negative_count = sum(all_child_text.count(keyword) for keyword in self.negative_keywords)
        
        # êµ¬ì²´ì ì¸ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        positive_found = [kw for kw in self.positive_keywords if kw in all_child_text]
        negative_found = [kw for kw in self.negative_keywords if kw in all_child_text]
        
        total = positive_count + negative_count
        
        return {
            'positive_count': positive_count,
            'negative_count': negative_count,
            'positive_ratio': (positive_count / total * 100) if total > 0 else 0,
            'negative_ratio': (negative_count / total * 100) if total > 0 else 0,
            'positive_keywords': list(set(positive_found)),
            'negative_keywords': list(set(negative_found)),
            'emotion_balance': 'positive' if positive_count > negative_count else ('negative' if negative_count > positive_count else 'neutral')
        }
    
    def extract_topic_keywords(self, top_n=20):
        """ì£¼ìš” í† í”½ í‚¤ì›Œë“œ ì¶”ì¶œ (ëª…ì‚¬ ì¤‘ì‹¬)"""
        child_texts = [d['text'] for d in self.dialogues if d['speaker_type'] == 'child']
        all_child_text = ' '.join(child_texts)
        
        # ê°„ë‹¨í•œ ëª…ì‚¬ ì¶”ì¶œ (í•œê¸€ 2ì ì´ìƒ ë‹¨ì–´)
        words = re.findall(r'[ê°€-í£]{2,}', all_child_text)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ì´ê±°', 'ì €ê±°', 'ê·¸ê±°', 'ì´ê²Œ', 'ì €ê²Œ', 'ê·¸ê²Œ', 'ìˆì–´', 'ì—†ì–´', 'ì´ë ‡ê²Œ', 'ì €ë ‡ê²Œ', 'ê·¸ë ‡ê²Œ']
        words = [w for w in words if w not in stopwords]
        
        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        word_freq = Counter(words)
        
        return {
            'top_keywords': word_freq.most_common(top_n),
            'unique_words': len(set(words)),
            'total_words': len(words)
        }
    
    def analyze_problem_solving(self):
        """ë¬¸ì œí•´ê²° ë°œí™” ë¶„ì„"""
        child_dialogues = [d for d in self.dialogues if d['speaker_type'] == 'child']
        
        problem_solving_utterances = []
        for d in child_dialogues:
            text = d['text']
            # ë¬¸ì œí•´ê²° í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë°œí™”
            if any(keyword in text for keyword in self.problem_solving_keywords):
                problem_solving_utterances.append(d)
        
        total_child_utterances = len(child_dialogues)
        ps_count = len(problem_solving_utterances)
        
        return {
            'problem_solving_count': ps_count,
            'problem_solving_ratio': (ps_count / total_child_utterances * 100) if total_child_utterances > 0 else 0,
            'examples': [u['text'] for u in problem_solving_utterances[:5]]  # ìƒìœ„ 5ê°œ ì˜ˆì‹œ
        }
    
    def analyze_topic_continuity(self):
        """ì£¼ì œ ì§€ì†ë„ ë¶„ì„ (ì„¸ê·¸ë¨¼íŠ¸ë³„ í‚¤ì›Œë“œ ì¤‘ë³µë„ ê¸°ë°˜)"""
        segments = defaultdict(list)
        
        # ì„¸ê·¸ë¨¼íŠ¸ë³„ë¡œ ì•„ë™ ë°œí™” ê·¸ë£¹í™”
        for d in self.dialogues:
            if d['speaker_type'] == 'child':
                segments[d['segment']].append(d['text'])
        
        segment_keywords = {}
        for seg, texts in segments.items():
            text = ' '.join(texts)
            words = re.findall(r'[ê°€-í£]{2,}', text)
            segment_keywords[seg] = set(words)
        
        # ì—°ì†ëœ ì„¸ê·¸ë¨¼íŠ¸ ê°„ í‚¤ì›Œë“œ ì¤‘ë³µë„ ê³„ì‚°
        segment_list = sorted(segment_keywords.keys())
        continuity_scores = []
        
        for i in range(len(segment_list) - 1):
            seg1 = segment_list[i]
            seg2 = segment_list[i + 1]
            
            kw1 = segment_keywords[seg1]
            kw2 = segment_keywords[seg2]
            
            if len(kw1) > 0 and len(kw2) > 0:
                # Jaccard ìœ ì‚¬ë„
                intersection = len(kw1 & kw2)
                union = len(kw1 | kw2)
                continuity = intersection / union if union > 0 else 0
                continuity_scores.append(continuity)
        
        return {
            'avg_continuity': statistics.mean(continuity_scores) if continuity_scores else 0,
            'continuity_std': statistics.stdev(continuity_scores) if len(continuity_scores) > 1 else 0,
            'total_segments': len(segment_list),
            'topic_changes': len([s for s in continuity_scores if s < 0.3])  # ë‚®ì€ ìœ ì‚¬ë„ = ì£¼ì œ ì „í™˜
        }
    
    def analyze_turn_taking(self):
        """í„´ í…Œì´í‚¹(ëŒ€í™” êµëŒ€) ë¶„ì„"""
        turns = []
        prev_speaker_type = None
        current_turn_length = 0
        
        for d in self.dialogues:
            if d['speaker_type'] != prev_speaker_type:
                if prev_speaker_type is not None:
                    turns.append({
                        'speaker_type': prev_speaker_type,
                        'length': current_turn_length
                    })
                prev_speaker_type = d['speaker_type']
                current_turn_length = 1
            else:
                current_turn_length += 1
        
        # ë§ˆì§€ë§‰ í„´ ì¶”ê°€
        if prev_speaker_type is not None:
            turns.append({
                'speaker_type': prev_speaker_type,
                'length': current_turn_length
            })
        
        child_turns = [t['length'] for t in turns if t['speaker_type'] == 'child']
        teacher_turns = [t['length'] for t in turns if t['speaker_type'] == 'teacher']
        
        return {
            'total_turns': len(turns),
            'child_turns': len(child_turns),
            'teacher_turns': len(teacher_turns),
            'avg_child_turn_length': statistics.mean(child_turns) if child_turns else 0,
            'avg_teacher_turn_length': statistics.mean(teacher_turns) if teacher_turns else 0,
            'turn_taking_balance': len(child_turns) / len(turns) if turns else 0
        }
    
    def generate_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print(f"ğŸ” ë¶„ì„ ì‹œì‘: {self.session_name}")
        
        # 1. ë©”íƒ€ ì •ë³´ ë¡œë“œ
        meta_info = self.load_meta_info()
        print(f"  - ë©”íƒ€ ì •ë³´ ë¡œë“œ ì™„ë£Œ")
        
        # 2. ëŒ€í™” ë°ì´í„° ë¡œë“œ
        self.load_all_dialogues()
        print(f"  - ëŒ€í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ì´ {len(self.dialogues)}ê°œ ë°œí™”")
        
        # 3. ê°ì¢… ë¶„ì„ ì‹¤í–‰
        analysis_results = {
            'meta_info': meta_info,
            'speech_ratio': self.analyze_speech_ratio(),
            'child_speech_amount': self.analyze_child_speech_amount(),
            'emotion_analysis': self.analyze_emotion_keywords(),
            'topic_keywords': self.extract_topic_keywords(20),
            'problem_solving': self.analyze_problem_solving(),
            'topic_continuity': self.analyze_topic_continuity(),
            'turn_taking': self.analyze_turn_taking(),
            'analyzed_at': datetime.now().isoformat()
        }
        
        print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
        
        return analysis_results
    
    def save_analysis(self, output_path):
        """ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        results = self.generate_full_analysis()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_path}")
        
        return results


def main():
    """ë©”ì¸ í•¨ìˆ˜ - ìƒ˜í”Œ ë¶„ì„"""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python analyze_play_session.py <session_directory>")
        print("\nì˜ˆì‹œ:")
        print("  python analyze_play_session.py raw_data/20251017-ì´ë¯¼ì •êµì‚¬-ê¹€ì¤€ìš°-ë§Œ4ì„¸-02_00_48-65kbps_mono")
        sys.exit(1)
    
    session_dir = sys.argv[1]
    
    # ë¶„ì„ê¸° ìƒì„±
    analyzer = PlaySessionAnalyzer(session_dir)
    
    # ë¶„ì„ ì‹¤í–‰ ë° ì €ì¥
    output_dir = Path("analysis_results")
    output_dir.mkdir(exist_ok=True)
    
    output_file = output_dir / f"{analyzer.session_name}_analysis.json"
    results = analyzer.save_analysis(output_file)
    
    # ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    print("\n" + "="*80)
    print("ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    
    print(f"\nğŸ‘¤ ê¸°ë³¸ ì •ë³´:")
    print(f"  - ì„ ìƒë‹˜: {results['meta_info'].get('teacher_name', 'N/A')}")
    print(f"  - ì•„ë™: {results['meta_info'].get('child_name', 'N/A')}")
    print(f"  - ë‚˜ì´: {results['meta_info'].get('child_age', 'N/A')}")
    
    print(f"\nğŸ’¬ ë°œí™” ë¶„ì„:")
    sr = results['speech_ratio']
    print(f"  - ì•„ë™ ë°œí™” ë¹„ìœ¨: {sr['child_speech_ratio']:.1f}%")
    print(f"  - ì•„ë™ ë°œí™” íšŸìˆ˜: {sr['child_utterance_count']}íšŒ")
    print(f"  - ì„ ìƒë‹˜ ë°œí™” íšŸìˆ˜: {sr['teacher_utterance_count']}íšŒ")
    
    print(f"\nğŸ“ ì•„ë™ ë°œí™”ëŸ‰:")
    ca = results['child_speech_amount']
    print(f"  - ì´ ë°œí™” íšŸìˆ˜: {ca['total_utterances']}íšŒ")
    print(f"  - ì´ ê¸€ì ìˆ˜: {ca['total_characters']}ì")
    print(f"  - í‰ê·  ë°œí™” ê¸¸ì´: {ca['avg_utterance_length']:.1f}ì")
    
    print(f"\nğŸ˜Š ê°ì • ë¶„ì„:")
    ea = results['emotion_analysis']
    print(f"  - ê¸ì • í‚¤ì›Œë“œ: {ea['positive_count']}ê°œ ({ea['positive_ratio']:.1f}%)")
    print(f"  - ë¶€ì • í‚¤ì›Œë“œ: {ea['negative_count']}ê°œ ({ea['negative_ratio']:.1f}%)")
    print(f"  - ê°ì • ê· í˜•: {ea['emotion_balance']}")
    print(f"  - ì£¼ìš” ê¸ì • í‚¤ì›Œë“œ: {', '.join(ea['positive_keywords'][:10])}")
    
    print(f"\nğŸ¯ ì£¼ì œ ë¶„ì„:")
    tk = results['topic_keywords']
    print(f"  - ê³ ìœ  ë‹¨ì–´ ìˆ˜: {tk['unique_words']}ê°œ")
    print(f"  - Top 10 í‚¤ì›Œë“œ:")
    for i, (word, count) in enumerate(tk['top_keywords'][:10], 1):
        print(f"    {i}. {word} ({count}íšŒ)")
    
    print(f"\nğŸ§© ë¬¸ì œí•´ê²° ë°œí™”:")
    ps = results['problem_solving']
    print(f"  - ë¬¸ì œí•´ê²° ë°œí™” ìˆ˜: {ps['problem_solving_count']}íšŒ")
    print(f"  - ë¬¸ì œí•´ê²° ë°œí™” ë¹„ìœ¨: {ps['problem_solving_ratio']:.1f}%")
    
    print(f"\nğŸ”„ ì£¼ì œ ì§€ì†ë„:")
    tc = results['topic_continuity']
    print(f"  - í‰ê·  ì—°ì†ì„±: {tc['avg_continuity']:.2f}")
    print(f"  - ì£¼ì œ ì „í™˜ íšŸìˆ˜: {tc['topic_changes']}íšŒ")
    print(f"  - ì´ ì„¸ê·¸ë¨¼íŠ¸: {tc['total_segments']}ê°œ")
    
    print(f"\nğŸ—£ï¸ ëŒ€í™” êµëŒ€:")
    tt = results['turn_taking']
    print(f"  - ì´ í„´ ìˆ˜: {tt['total_turns']}íšŒ")
    print(f"  - ì•„ë™ í‰ê·  í„´ ê¸¸ì´: {tt['avg_child_turn_length']:.1f}íšŒ")
    print(f"  - ì„ ìƒë‹˜ í‰ê·  í„´ ê¸¸ì´: {tt['avg_teacher_turn_length']:.1f}íšŒ")
    
    print("\n" + "="*80)


if __name__ == "__main__":
    main()

