"""
ì „ì²´ ë¶„ì„ ë° ë ˆí¬íŠ¸ ìƒì„± ì›Œí¬í”Œë¡œìš°
- VTT íŒŒì¼ ë¶„ì„
- ì§€í‘œ ê³„ì‚°
- 3ê°€ì§€ ë ˆí¬íŠ¸ + ë°©ë¬¸ì¼ì§€ ìƒì„±
"""

import os
import sys
from datetime import datetime
from enhanced_analysis import analyze_session
from report_generator import ReportGenerator


def run_full_pipeline(session_path: str, output_base_dir: str = None):
    """
    ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    
    Args:
        session_path: ì„¸ì…˜ í´ë” ê²½ë¡œ
        output_base_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: í”„ë¡œì íŠ¸ ë£¨íŠ¸)
    """
    if output_base_dir is None:
        output_base_dir = os.path.dirname(os.path.abspath(__file__))
    
    session_name = os.path.basename(session_path)
    
    print("\n" + "="*70)
    print(f"ğŸš€ ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    print("="*70)
    print(f"ğŸ“ ì„¸ì…˜: {session_name}")
    print(f"ğŸ“‚ ì¶œë ¥ ê²½ë¡œ: {output_base_dir}")
    print("="*70 + "\n")
    
    # Step 1: ë¶„ì„ ì‹¤í–‰
    print("ã€STEP 1ã€‘ ë°ì´í„° ë¶„ì„ ì¤‘...")
    print("-" * 70)
    
    try:
        analysis_dir = os.path.join(output_base_dir, 'analysis_results')
        analyzer, analysis_file = analyze_session(session_path, analysis_dir)
        print(f"âœ… ë¶„ì„ ì™„ë£Œ: {analysis_file}\n")
    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None
    
    # Step 2: ë ˆí¬íŠ¸ ìƒì„±
    print("ã€STEP 2ã€‘ ë ˆí¬íŠ¸ ìƒì„± ì¤‘...")
    print("-" * 70)
    
    try:
        reports_dir = os.path.join(output_base_dir, 'reports')
        generator = ReportGenerator(analysis_file)
        report_files = generator.save_all_reports(reports_dir)
        print()
    except Exception as e:
        print(f"âŒ ë ˆí¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None
    
    # Step 3: ìš”ì•½
    print("\nã€STEP 3ã€‘ ì™„ë£Œ ìš”ì•½")
    print("="*70)
    print("\nğŸ“Š ìƒì„±ëœ íŒŒì¼:")
    print(f"  1. ë¶„ì„ ë°ì´í„°: {analysis_file}")
    print(f"  2. ë¶€ëª¨ìš© ë ˆí¬íŠ¸: {report_files['parent']}")
    print(f"  3. ì„ ìƒë‹˜ìš© ë ˆí¬íŠ¸: {report_files['teacher']}")
    print(f"  4. ë°©ë¬¸ì¼ì§€: {report_files['journal']}")
    print(f"  5. íšŒì‚¬ìš© ë ˆí¬íŠ¸: {report_files['company']}")
    
    print("\nğŸ“ˆ í•µì‹¬ ì§€í‘œ:")
    metrics = analyzer.analysis_results
    print(f"  â€¢ ì•„ë™ ë°œí™” ë¹„ìœ¨: {metrics['child_utterance_ratio']:.1%}")
    print(f"  â€¢ ì•„ë™ ë°œí™” ìˆ˜: {metrics['child_utterance_count']}íšŒ")
    print(f"  â€¢ í‰ê·  ë°œí™” ê¸¸ì´: {metrics['child_avg_words_per_utterance']:.1f} ë‹¨ì–´")
    print(f"  â€¢ ë¬¸ì œí•´ê²° ë°œí™”: {metrics['problem_solving_utterances']['child_count']}íšŒ")
    print(f"  â€¢ ì£¼ì œ ì§€ì†ë„: {metrics['topic_persistence']:.2f}")
    print(f"  â€¢ ê¸ì •/ë¶€ì • ë¹„ìœ¨: {metrics['positive_negative_ratio']:.2f}")
    
    print("\n" + "="*70)
    print("âœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("="*70 + "\n")
    
    return {
        'analysis_file': analysis_file,
        'reports': report_files,
        'metrics': metrics
    }


def batch_process_sessions(raw_data_dir: str, output_base_dir: str = None, limit: int = None):
    """
    ì—¬ëŸ¬ ì„¸ì…˜ ì¼ê´„ ì²˜ë¦¬
    
    Args:
        raw_data_dir: raw_data ë””ë ‰í† ë¦¬ ê²½ë¡œ
        output_base_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        limit: ì²˜ë¦¬í•  ì„¸ì…˜ ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)
    """
    if output_base_dir is None:
        output_base_dir = os.path.dirname(os.path.abspath(__file__))
    
    print("\n" + "="*70)
    print("ğŸ”„ ì¼ê´„ ì²˜ë¦¬ ëª¨ë“œ")
    print("="*70 + "\n")
    
    # ì„¸ì…˜ í´ë” ì°¾ê¸°
    sessions = []
    for item in os.listdir(raw_data_dir):
        item_path = os.path.join(raw_data_dir, item)
        if os.path.isdir(item_path) and not item.endswith('.zip'):
            # VTT í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸
            vtt_path = os.path.join(item_path, 'vtt')
            if os.path.exists(vtt_path):
                sessions.append(item_path)
    
    sessions.sort()
    
    if limit:
        sessions = sessions[:limit]
    
    print(f"ğŸ“¦ ë°œê²¬ëœ ì„¸ì…˜: {len(sessions)}ê°œ")
    if limit:
        print(f"ğŸ“ ì²˜ë¦¬í•  ì„¸ì…˜: {limit}ê°œ\n")
    else:
        print(f"ğŸ“ ëª¨ë“  ì„¸ì…˜ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n")
    
    results = []
    success_count = 0
    fail_count = 0
    
    for i, session_path in enumerate(sessions, 1):
        session_name = os.path.basename(session_path)
        
        print(f"\n{'â–¶'*3} [{i}/{len(sessions)}] {session_name}")
        print("-" * 70)
        
        try:
            result = run_full_pipeline(session_path, output_base_dir)
            if result:
                results.append({
                    'session': session_name,
                    'status': 'success',
                    'result': result
                })
                success_count += 1
            else:
                results.append({
                    'session': session_name,
                    'status': 'failed',
                    'result': None
                })
                fail_count += 1
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
            results.append({
                'session': session_name,
                'status': 'error',
                'error': str(e)
            })
            fail_count += 1
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*70)
    print("ğŸ ì¼ê´„ ì²˜ë¦¬ ì™„ë£Œ")
    print("="*70)
    print(f"\nì´ {len(sessions)}ê°œ ì„¸ì…˜ ì²˜ë¦¬:")
    print(f"  âœ… ì„±ê³µ: {success_count}ê°œ")
    print(f"  âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    
    if fail_count > 0:
        print("\nì‹¤íŒ¨í•œ ì„¸ì…˜:")
        for r in results:
            if r['status'] != 'success':
                print(f"  â€¢ {r['session']}: {r.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    print("\n" + "="*70 + "\n")
    
    return results


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë†€ì´ ì„¸ì…˜ ë¶„ì„ ë° ë ˆí¬íŠ¸ ìƒì„±')
    parser.add_argument('--session', type=str, help='ë‹¨ì¼ ì„¸ì…˜ í´ë” ê²½ë¡œ')
    parser.add_argument('--batch', action='store_true', help='ì¼ê´„ ì²˜ë¦¬ ëª¨ë“œ')
    parser.add_argument('--raw-data-dir', type=str, 
                       default='/Users/healin/Downloads/develop/care-intell/raw_data',
                       help='raw_data ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--output-dir', type=str, help='ì¶œë ¥ ë””ë ‰í† ë¦¬')
    parser.add_argument('--limit', type=int, help='ì²˜ë¦¬í•  ì„¸ì…˜ ìˆ˜ ì œí•œ')
    
    args = parser.parse_args()
    
    if args.session:
        # ë‹¨ì¼ ì„¸ì…˜ ì²˜ë¦¬
        run_full_pipeline(args.session, args.output_dir)
    elif args.batch:
        # ì¼ê´„ ì²˜ë¦¬
        batch_process_sessions(args.raw_data_dir, args.output_dir, args.limit)
    else:
        # ê¸°ë³¸: ì²« ë²ˆì§¸ ì„¸ì…˜ ì²˜ë¦¬ (í…ŒìŠ¤íŠ¸)
        session_path = '/Users/healin/Downloads/develop/care-intell/raw_data/20251017-ì´ë¯¼ì •êµì‚¬-ê¹€ì¤€ìš°-ë§Œ4ì„¸-02_00_48-65kbps_mono'
        run_full_pipeline(session_path)


if __name__ == '__main__':
    main()




